{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sk1rbi15nILf"
   },
   "source": [
    "*# даLL-E x CLIP*\n",
    "\n",
    "Aleph2Image by @Advadnoun aka Ryan Murdoch - Visit [here](https://www.patreon.com/patronizeme) and make the decision to support these notebook developments into the cutting edge. \n",
    "______________\n",
    "---\n",
    "###Notebook Modified by Fractal DNA\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXkWz0-SyY5X",
    "outputId": "270e68e6-6ba2-405f-e12d-72b5c81b794c"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nvcc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-52804e97dc11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mCUDA_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"nvcc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"--version\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\", \"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"release\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDA version:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCUDA_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mcheck_output\u001b[0;34m(timeout, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'universal_newlines'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m     return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n\u001b[0m\u001b[1;32m    412\u001b[0m                **kwargs).stdout\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stderr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    852\u001b[0m                             encoding=encoding, errors=errors)\n\u001b[1;32m    853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[1;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                                 \u001b[0mstartupinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreationflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1700\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0merrno_num\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m                         \u001b[0merr_msg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mchild_exception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nvcc'"
     ]
    }
   ],
   "source": [
    "#@title  <== FIRST TIME?  *RUN* then restart  Runtime* \n",
    "\n",
    "import subprocess\n",
    "\n",
    "torch_version_suffix = \"+cu110\"\n",
    "\n",
    "!pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "id": "TydMLXWFwPOe"
   },
   "outputs": [],
   "source": [
    "#@title Capacitating Genetic Modifiers\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import imageio\n",
    "from IPython import display\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import torch.contrib\n",
    "import glob\n",
    "\n",
    "from google.colab import output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSYypc9HwR8F",
    "outputId": "8afb9d7a-d7e5-4867-f96d-38941b3ac25c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content\n",
      "Cloning into 'DALL-E'...\n",
      "remote: Enumerating objects: 3, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 18\u001b[K\n",
      "Unpacking objects: 100% (21/21), done.\n",
      "Cloning into 'CLIP'...\n",
      "remote: Enumerating objects: 12, done.\u001b[K\n",
      "remote: Counting objects: 100% (12/12), done.\u001b[K\n",
      "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
      "remote: Total 86 (delta 5), reused 8 (delta 4), pack-reused 74\u001b[K\n",
      "Unpacking objects: 100% (86/86), done.\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-m_fzpdpw\n",
      "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-m_fzpdpw\n",
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (5.9)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (2019.12.20)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (4.41.1)\n",
      "Requirement already satisfied: torch~=1.7.1 in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (1.7.1+cu110)\n",
      "Requirement already satisfied: torchvision~=0.8.2 in /usr/local/lib/python3.7/dist-packages (from clip==1.0) (0.8.2+cu110)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->clip==1.0) (0.2.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch~=1.7.1->clip==1.0) (3.7.4.3)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision~=0.8.2->clip==1.0) (7.1.2)\n",
      "Building wheels for collected packages: clip\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for clip: filename=clip-1.0-cp37-none-any.whl size=1368708 sha256=c08062564f8df3d3938c880b65c3af7ffcbcee0831066be221648fca18b7d90e\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-icby3svu/wheels/79/51/d7/69f91d37121befe21d9c52332e04f592e17d1cabc7319b3e09\n",
      "Successfully built clip\n",
      "Installing collected packages: clip\n",
      "Successfully installed clip-1.0\n",
      "Collecting git+https://github.com/openai/DALL-E.git\n",
      "  Cloning https://github.com/openai/DALL-E.git to /tmp/pip-req-build-4bseu1ci\n",
      "  Running command git clone -q https://github.com/openai/DALL-E.git /tmp/pip-req-build-4bseu1ci\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from DALL-E==0.1) (7.1.2)\n",
      "Collecting blobfile\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/ac/e19aa596b3b23260f15c5a4016b4fd902af595da41a403e47dde9756c1fc/blobfile-1.1.2-py3-none-any.whl (60kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 5.4MB/s \n",
      "\u001b[?25hCollecting mypy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/f0/6b01da1ffc9322ab3844c0138b3256fefba30eac889731ca74c671a7e66e/mypy-0.812-cp37-cp37m-manylinux2010_x86_64.whl (21.6MB)\n",
      "\u001b[K     |████████████████████████████████| 21.6MB 1.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from DALL-E==0.1) (1.19.5)\n",
      "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from DALL-E==0.1) (3.6.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from DALL-E==0.1) (2.23.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from DALL-E==0.1) (1.7.1+cu110)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from DALL-E==0.1) (0.8.2+cu110)\n",
      "Collecting xmltodict~=0.12.0\n",
      "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: filelock~=3.0 in /usr/local/lib/python3.7/dist-packages (from blobfile->DALL-E==0.1) (3.0.12)\n",
      "Collecting pycryptodomex~=3.8\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/9d/99a949925b5fc9604cb65219951fd270ef30d0fd4f064d1b363eb8bb5e9b/pycryptodomex-3.10.1-cp35-abi3-manylinux2010_x86_64.whl (1.9MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9MB 55.9MB/s \n",
      "\u001b[?25hCollecting urllib3~=1.25\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/c6/d3e3abe5b4f4f16cf0dfc9240ab7ce10c2baa0e268989a4e3ec19e90c84e/urllib3-1.26.4-py2.py3-none-any.whl (153kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 21.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from mypy->DALL-E==0.1) (3.7.4.3)\n",
      "Collecting mypy-extensions<0.5.0,>=0.4.3\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/eb/975c7c080f3223a5cdaff09612f3a5221e4ba534f7039db34c35d95fa6a5/mypy_extensions-0.4.3-py2.py3-none-any.whl\n",
      "Collecting typed-ast<1.5.0,>=1.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/76/04c8d23cf9da13b6c892055148cdabb79d8d835dd816d09d529c1c615b20/typed_ast-1.4.2-cp37-cp37m-manylinux1_x86_64.whl (743kB)\n",
      "\u001b[K     |████████████████████████████████| 747kB 52.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E==0.1) (1.4.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E==0.1) (1.10.0)\n",
      "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E==0.1) (0.7.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E==0.1) (54.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E==0.1) (20.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E==0.1) (1.15.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->DALL-E==0.1) (8.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->DALL-E==0.1) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->DALL-E==0.1) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->DALL-E==0.1) (3.0.4)\n",
      "Building wheels for collected packages: DALL-E\n",
      "  Building wheel for DALL-E (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for DALL-E: filename=DALL_E-0.1-cp37-none-any.whl size=6000 sha256=4083592d6f5c7beb589e90579c458f6d8956cdf4b7e8971a881ff418e2c3a676\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qxlyx3yi/wheels/e9/f5/e7/efa7ddb4c5899f6e6ffbbd112b8c7a030872274a5cba9ccf04\n",
      "Successfully built DALL-E\n",
      "\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "Installing collected packages: xmltodict, pycryptodomex, urllib3, blobfile, mypy-extensions, typed-ast, mypy, DALL-E\n",
      "  Found existing installation: urllib3 1.24.3\n",
      "    Uninstalling urllib3-1.24.3:\n",
      "      Successfully uninstalled urllib3-1.24.3\n",
      "Successfully installed DALL-E-0.1 blobfile-1.1.2 mypy-0.812 mypy-extensions-0.4.3 pycryptodomex-3.10.1 typed-ast-1.4.2 urllib3-1.26.4 xmltodict-0.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.4) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n",
      "100%|███████████████████████████████████████| 354M/354M [00:05<00:00, 65.4MiB/s]\n"
     ]
    }
   ],
   "source": [
    "#@title Preparing Captive Simulators  \n",
    "%cd /content/\n",
    "!git clone https://github.com/openai/DALL-E.git\n",
    "!git clone https://github.com/openai/CLIP.git\n",
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "!pip install git+https://github.com/openai/DALL-E.git\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "from google.colab import files\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from CLIP import clip\n",
    "from dall_e import utils, encoder, decoder\n",
    "\n",
    "dev = torch.device('cuda:0')\n",
    "\n",
    "# Load the model\n",
    "perceptor, preprocess = clip.load('ViT-B/32', dev, jit=True)\n",
    "perceptor = perceptor.train() #or .eval() instead of .train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "RrZV70kDwgn-"
   },
   "outputs": [],
   "source": [
    "#@title Chlorinating Car Pools\n",
    "im_shape = [512, 512, 3]\n",
    "sideX, sideY, channels = im_shape\n",
    "\n",
    "def displ(img, pre_scaled=True):\n",
    "  img = np.array(img)[:,:,:]\n",
    "  img = np.transpose(img, (1, 2, 0))\n",
    "  if not pre_scaled:\n",
    "    img = scale(img, 32*4, 32*4)\n",
    "  imageio.imwrite(str(3) + '.png', np.array(img))\n",
    "  return display.Image(str(3)+'.png')\n",
    "\n",
    "def gallery(array, ncols=16):\n",
    "    nindex, height, width, intensity = array.shape\n",
    "    nrows = nindex//ncols\n",
    "    assert nindex == nrows*ncols\n",
    "    # want result.shape = (height*nrows, width*ncols, intensity)\n",
    "    result = (array.reshape(nrows, ncols, height, width, intensity)\n",
    "              .swapaxes(1,2)\n",
    "              .reshape(height*nrows, width*ncols, intensity))\n",
    "    return result\n",
    "\n",
    "def card_padded(im, to_pad=2):\n",
    "  return np.pad(np.pad(np.pad(im, [[1,1], [1,1], [0,0]],constant_values=0), [[2,2], [2,2], [0,0]],constant_values=1),\n",
    "            [[to_pad,to_pad], [to_pad,to_pad], [0,0]],constant_values=0)\n",
    "\n",
    "def get_all(img):\n",
    "  img = np.transpose(img, (0,2,3,1))\n",
    "  cards = np.zeros((img.shape[0], sideX+12, sideY+12, 3))\n",
    "  for i in range(len(img)):\n",
    "    cards[i] = card_padded(img[i])\n",
    "  print(img.shape)\n",
    "  cards = gallery(cards)\n",
    "  imageio.imwrite(str(3) + '.png', np.array(cards))\n",
    "  return display.Image(str(3)+'.png')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "FVjZ65I-wiOO"
   },
   "outputs": [],
   "source": [
    "#@title Reticulating 3 1-dimensional-splines\n",
    "\n",
    "import io\n",
    "import os, sys\n",
    "import requests\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "%cd DALL-E\n",
    "\n",
    "from dall_e import map_pixels, unmap_pixels, load_model\n",
    "target_image_size = sideX\n",
    "\n",
    "def preprocess(img):\n",
    "    s = min(img.size)\n",
    "    \n",
    "    if s < target_image_size:\n",
    "        raise ValueError(f'min dim for image {s} < {target_image_size}')\n",
    "        \n",
    "    r = target_image_size / s\n",
    "    s = (round(r * img.size[1]), round(r * img.size[0]))\n",
    "    img = TF.resize(img, s, interpolation=PIL.Image.LANCZOS)\n",
    "    img = TF.center_crop(img, output_size=2 * [target_image_size])\n",
    "    img = torch.unsqueeze(T.ToTensor()(img), 0)\n",
    "    return map_pixels(img)\n",
    "\n",
    "dev = torch.device('cuda:0')\n",
    "\n",
    "model = load_model(\"https://cdn.openai.com/dall-e/decoder.pkl\", dev)\n",
    "\n",
    "enc = load_model(\"https://cdn.openai.com/dall-e/encoder.pkl\", dev)\n",
    "\n",
    "\n",
    "\n",
    "#x = (torch.zeros(1, 3, 512, 512))\n",
    "\n",
    "\n",
    "#z_logits = enc(x.to(dev))\n",
    "#z = torch.argmax(z_logits, axis=1)\n",
    "#z = torch.nn.functional.one_hot(z, num_classes=enc.vocab_size).permute(0, 3, 1, 2).float()\n",
    "\n",
    "%cd /content/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "tSeQKLUwNKBy"
   },
   "outputs": [],
   "source": [
    "#@title 1. Enter Text\n",
    "\n",
    "text_input = \"a traffic light with pink purple and blue lights on empty street\" #@param {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "SF7zUDIawwMO"
   },
   "outputs": [],
   "source": [
    "#@title ###2 <---- Normu the Latent Phase-Space\n",
    "\n",
    "class Pars(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Pars, self).__init__()\n",
    "        self.normu = torch.nn.Parameter(torch.randn(1, 8192, 64, 64).to(dev))\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        normu = torch.nn.functional.gumbel_softmax(self.normu.view(1, 8192, -1), tau=1.7, dim=-1).view(1, 8192, 64, 64)\n",
    "        return normu\n",
    "\n",
    "\n",
    "lats = Pars().cuda()\n",
    "mapper = [lats.normu]\n",
    "optimizer = torch.optim.Adam([{'params': mapper, 'lr': .1}])\n",
    "eps = 4\n",
    "\n",
    "\n",
    "tx = clip.tokenize(text_input)\n",
    "t = perceptor.encode_text(tx.to(dev)).detach().clone()\n",
    "\n",
    "\n",
    "nom = torchvision.transforms.Normalize((0.58145466, 0.5578275, 0.50821073), (0.26862954, 0.26130258, 0.27577711))\n",
    "\n",
    "with torch.no_grad():\n",
    "  mult = 1\n",
    "  al = unmap_pixels(torch.sigmoid(model(lats()).cpu().float())).numpy()\n",
    "  for allls in al:\n",
    "    displ(allls[:3])\n",
    "    print('\\n')\n",
    "    print(torch.topk(lats().view(1, 8192, -1), k=64, dim=-1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2eMfVI5vhHv"
   },
   "source": [
    "# ***Image Generation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6SQtx5Aw5I-"
   },
   "outputs": [],
   "source": [
    "#@title #### <---  3 ---  Generate Images { vertical-output: true, form-width: \"30%\", display-mode: \"both\" }\n",
    "\n",
    "def checkin(loss):\n",
    "  print(itt, loss,'\\n', text_input,'\\n') \n",
    "  with torch.no_grad():\n",
    "    al = unmap_pixels(torch.sigmoid(model(lats())[:, :3]).cpu().float()).numpy()\n",
    "  for allls in al:\n",
    "    nom\n",
    "    displ(allls)\n",
    "    display.display(display.Image(str(3)+'.png'))\n",
    "    print('\\n')\n",
    "\n",
    " \n",
    " \n",
    "def ascend_txt():\n",
    "  out = unmap_pixels(torch.sigmoid(model(lats())[:, :3].float())) \n",
    "  mean=0.323 #@param {type:\"slider\", min:0.001, max:1, step:0.001}\n",
    "  std = 0.837 #@param {type:\"slider\", min:0.001, max:1, step:0.001}\n",
    "\n",
    "  tau = 1.733 #@param {type:\"slider\", min:0.5, max:16, step:0.001}\n",
    "  min = 0.05 #@param {type:\"slider\", min:0.05, max:0.5, step:0.0001}\n",
    "  max = 0.7992 #@param {type:\"slider\", min:0.5, max:0.98, step:0.0001}\n",
    "\n",
    "  cutn = 32 #@param {type:\"slider\", min:1, max:128, step:1}\n",
    "  cutn = 32\n",
    "  p_s = []\n",
    "  for  ch in range(cutn):\n",
    "    size = int(sideX*torch.zeros(1).normal_(mean, std=.86).clip(.3, .80))\n",
    "    offsetx = torch.randint(0, sideX - size, ())\n",
    "    offsety = torch.randint(0, sideX - size, ())\n",
    "    apper = out[:, :, offsetx:offsetx + size, offsety:offsety + size]\n",
    "    apper = torch.nn.functional.interpolate(apper, (224,224), mode='nearest')\n",
    "    p_s.append(apper)\n",
    "  into = torch.cat(p_s, 0)\n",
    "  \n",
    "  into = nom((into + 1) / tau)\n",
    "  \n",
    "  iii = perceptor.encode_image(into)\n",
    " \n",
    "  llls = lats()\n",
    "  lat_l = 0\n",
    " \n",
    "  return [lat_l, 100*-torch.cosine_similarity(t, iii).view(-1, 1).T.mean(1)]\n",
    "\n",
    "  \n",
    "\n",
    "def train(i):\n",
    "  loss1 = ascend_txt()\n",
    "  loss = loss1[0] + loss1[1]\n",
    "  loss = loss.mean()\n",
    "  optimizer.zero_grad( )\n",
    "  loss.backward(retain_graph=False)\n",
    "  optimizer.step()\n",
    "\n",
    "  g_lr = 0.1325 #@param {type:\"slider\", min:0.0005, max:0.95, step:0.0005}\n",
    "  up_noise = 0.03893 #@param {type:\"slider\", min:0.00001, max:0.99999, step:0.00001}\n",
    "  \n",
    "\n",
    "  if itt % 10 == 0:\n",
    "    checkin(loss1)\n",
    "\n",
    "iterations = 10000 #@param {type:\"number\"} \n",
    " \n",
    "itt = 0\n",
    "for asatreat in range(iterations):\n",
    "  train(itt)\n",
    "  itt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FpEzjVfBDVBM"
   },
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "image_input = 'image.jpg'\n",
    "PIL.Image.open(image_input)\n",
    "img = 2.*img - 1.\n",
    "img = img.to(dev)\n",
    "iii = perceptor.encode_image(iii)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DALL-E with Text Generation",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
